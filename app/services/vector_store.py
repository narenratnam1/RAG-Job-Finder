"""
Vector store service using Pinecone with client-side OpenAI embeddings
"""

import os
import time
from typing import List, Dict, Any
import uuid
from dotenv import load_dotenv

# Load environment variables before anything else
load_dotenv()

# Import Pinecone and LangChain Pinecone
try:
    from pinecone import Pinecone, ServerlessSpec
    from langchain_pinecone import PineconeVectorStore
    PINECONE_AVAILABLE = True
except ImportError as e:
    PINECONE_AVAILABLE = False
    raise ImportError(f"Pinecone is required. Install with: pip install pinecone-client langchain-pinecone") from e

# Import OpenAI Embeddings for client-side embedding generation
try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_EMBEDDINGS_AVAILABLE = True
except ImportError as e:
    OPENAI_EMBEDDINGS_AVAILABLE = False
    raise ImportError(f"OpenAI embeddings required. Install with: pip install langchain-openai") from e


class VectorService:
    """Service for managing vector store operations with Pinecone"""
    
    def __init__(self):
        """Initialize Pinecone vector store"""
        # Check for Pinecone configuration
        pinecone_api_key = os.getenv("PINECONE_API_KEY")
        pinecone_index_name = os.getenv("PINECONE_INDEX_NAME", "resume-index")
        
        print(f"ðŸ” DEBUG: PINECONE_API_KEY={'SET' if pinecone_api_key else 'NOT SET'}")
        print(f"ðŸ” DEBUG: PINECONE_INDEX_NAME={pinecone_index_name}")
        
        # Validate Pinecone credentials
        if not pinecone_api_key or pinecone_api_key == "your_pinecone_api_key_here":
            raise ValueError(
                "PINECONE_API_KEY is required. Please set it in your .env file.\n"
                "Get your API key from: https://app.pinecone.io/"
            )
        
        # Initialize Pinecone
        try:
            self._init_pinecone(pinecone_api_key, pinecone_index_name)
            self.backend = "pinecone"
            print(f"âœ“ VectorService initialized with Pinecone (index: {pinecone_index_name})")
        except Exception as e:
            print(f"âŒ Pinecone initialization failed: {e}")
            raise RuntimeError(f"Failed to initialize Pinecone: {e}") from e
    
    def _init_pinecone(self, api_key: str, index_name: str):
        """Initialize Pinecone vector store with CLIENT-SIDE OpenAI embeddings"""
        # Initialize Pinecone client
        self.pc = Pinecone(api_key=api_key)
        self.index_name = index_name
        
        # Initialize OpenAI embeddings for CLIENT-SIDE generation
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key or openai_api_key == "your_openai_api_key_here":
            raise Exception("OPENAI_API_KEY required for Pinecone client-side embeddings")
        
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",  # 1536 dimensions
            api_key=openai_api_key
        )
        print(f"  Using OpenAI embeddings (text-embedding-3-small, 1536d)")
        
        # Check if index exists
        existing_indexes = [index.name for index in self.pc.list_indexes()]
        
        if index_name not in existing_indexes:
            print(f"âš ï¸  Index '{index_name}' not found. Creating...")
            # Create index with correct dimension for OpenAI embeddings
            self.pc.create_index(
                name=index_name,
                dimension=1536,  # text-embedding-3-small dimension
                metric="cosine",
                spec=ServerlessSpec(
                    cloud="aws",
                    region="us-east-1"
                )
            )
            print(f"âœ“ Created Pinecone index: {index_name}")
            # Wait for index to be ready
            time.sleep(5)
        
        # Initialize LangChain PineconeVectorStore with CLIENT-SIDE embeddings
        self.vectorstore = PineconeVectorStore(
            index_name=index_name,
            embedding=self.embeddings,  # CRITICAL: Client-side embeddings
            pinecone_api_key=api_key
        )
        
        # Get index stats for verification
        index = self.pc.Index(index_name)
        stats = index.describe_index_stats()
        print(f"  Index stats: {stats.get('total_vector_count', 0)} vectors")
    
    
    def add_documents(self, texts: List[str], metadatas: List[dict]) -> None:
        """
        Add documents to the Pinecone vector store
        
        Args:
            texts: List of text chunks to save
            metadatas: List of metadata dictionaries for each chunk
        """
        # Use LangChain's add_texts method with CLIENT-SIDE OpenAI embeddings
        # The embeddings are generated by OpenAI (client-side), NOT Pinecone inference
        self.vectorstore.add_texts(
            texts=texts,
            metadatas=metadatas
        )
        print(f"âœ“ Added {len(texts)} documents to Pinecone (client-side OpenAI embeddings)")
    
    def search(self, query: str, k: int = 3) -> List[Dict[str, Any]]:
        """
        Retrieve similar chunks from Pinecone based on query
        
        Args:
            query: The search query string
            k: Number of similar chunks to retrieve (default: 3)
        
        Returns:
            List of dictionaries containing similar documents with metadata
        """
        # Use LangChain's similarity_search_with_score
        # Embeddings are generated CLIENT-SIDE by OpenAI, NOT by Pinecone inference
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        
        # Format results
        formatted_results: List[Dict[str, Any]] = []
        for doc, score in results:
            formatted_results.append({
                "id": doc.metadata.get("id", str(uuid.uuid4())),
                "text": doc.page_content,
                "metadata": doc.metadata,
                "distance": 1 - score,  # Convert similarity score to distance
                "score": score
            })
        
        return formatted_results
    
    def delete_namespace(self, namespace: str) -> bool:
        """
        Delete all records in a namespace (Pinecone only)
        Note: When using client-side embeddings, namespaces are handled by LangChain
        and deletion is not directly supported. Use Pinecone dashboard instead.
        
        Args:
            namespace: The namespace to delete
        
        Returns:
            False (not supported with client-side embeddings)
        """
        print("âš ï¸  Namespace deletion not directly supported with client-side embeddings")
        print("   Use Pinecone dashboard to delete specific vectors by metadata filters")
        return False
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the Pinecone vector store
        
        Returns:
            Dictionary with stats about the vector store
        """
        index = self.pc.Index(self.index_name)
        stats = index.describe_index_stats()
        return {
            "backend": "pinecone",
            "index_name": self.index_name,
            "total_vectors": stats.get('total_vector_count', 0),
            "dimension": 1536,
            "embedding_model": "text-embedding-3-small (OpenAI)"
        }
